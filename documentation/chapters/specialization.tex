\section{Specialization}\label{specialize}
This section summarizes from the development in Vose (see \cite{Vose1999}).
It specializes the haploid evolution equations in the previous section 
to a context where mask-based crossing over and mutation operators are used, 
leading to Vose's infinite population model for Genetic Algorithms.  Whereas 
in previous sections {\em component} referred to a component
of a distribution vector $q^n$ or $p^n$, in this section a component
is either a probability (when when speaking of a component of a
distribution vector), or a bit (when speaking of a component of a
haploid).
% The set of haploids (i.e., length $\ell$ binary strings) is a
% commutative ring $\mathcal{R}$ under component-wise addition and
% multiplication modulo $2$. This algebraic structure is crucial to
% Vose's specialization and subsequent analysis of
% (\ref{model3}). If $x \in \mathcal{R}$, then $x = \langle x_0, x_1, .., x_{\ell - 1} \rangle$. 
% Denote the additive identity by ${\bf 0}$ and the
% multiplicative identity by ${\bf 1}$, and let $\overline{g}$
% abbreviate ${\bf 1} + g$.  Except when explicitly indicated otherwise,
% operations acting on elements of $\mathcal{R}$ are as defined in this
% paragraph.\footnote{In particular, $g \overline{g} = {\bf 0} = g+g$,
%   $g^2 = g$, $g + \overline{g} = {\bf 1}$ for all $g \in
%   \mathcal{R}$.}

\subsection{Mutation}
Mutation simulates low probability errors in chromosome duplication. 
Mutation provides a mechanism to inject new strings into the next generation.
The symbol $\bm{\mu}$ denotes mutation distribution describing 
the probability $\bm{\mu}_i$ with which $i \in \Omega$ is selected to be a mutation mask. 
The result of mutating $g$ is $g + i$ with probability $\bm{\mu}_i$. 
Mutating $g$ using mutation mask $i$ alters the bits of $g$ in those positions the mutation mask $i$ is 1. 
If $g$ should mutate to $g^\prime$ with probability $\rho$,
let\\[-0.2in]
\[
\bm{\mu}_{g + g^\prime} \; = \; \rho\\[0.05in]
\]
Given distribution $\bm{\mu}$, mutation is the stochastic operator sending
$g$ to $g^\prime$ with probability $\bm{\mu}_{g + g^\prime}$.
Abusing notation, $\bm{\mu} \in [0, 0.5)$ is regarded as a {\em mutation rate} which implicitly 
specifies distribution $\bm{\mu}$ according to the rule (see \cite{VoseWright1998})
\[
\bm{\mu}_i = (\bm{\mu})^{{\bf 1}^Ti} (1-\bm{\mu})^{\ell- {\bf 1}^Ti}
\]

\subsection{Crossover}
Crossover refers to crossing over (also termed recombination) between two chromosomes (strings in our case). 
Crossover like mutation also provides a mechanism for injection of new strings into the next generation population. 
Geiringer (see \cite{Geiringer1944}) used crossover masks to generate offsprings from parent chromosomes 
in absence of mutation and selection. Let $\bm{\chi}_m$ be the probability distribution with which $m$ is 
selected to be a crossover mask. Following Geiringer (see \cite{Geiringer1944}), if crossing over $u$ and $v$ 
should produce $u^\prime$ and $v^\prime$ with probability $\rho$, let
\[
\bm{\chi}_m \; = \; \rho
\]
where $m$ is $1$ at components which $u^\prime$ inherits from $u$, and
$0$ at components inherited from $v$.  It follows that\\[-0.3in]
\begin{eqnarray*}
u^\prime & = & m \nudge u + \overline{m} \nudge\nudge v \\
v^\prime & = & m \nudge v + \overline{m} \nudge\nudge u
\end{eqnarray*}
Given distribution $\bm{\chi}$, crossover is the stochastic operator which
sends $u$ and $v$ to $u^\prime$ and $v^\prime$ with probability $\bm{\chi}_m/2$.

Abusing notation, $\bm{\chi}$ can be considered as a {\em crossover rate} that specifies 
the distribution $\bm{\chi}$ given by the rule (see \cite{VoseWright1998})
\[
  \bm{\chi}_i =\begin{cases}
    \bm{\chi}  c_i & \text{if $i>0$}.\\
    1 - \bm{\chi} + \bm{\chi}  c_0 & \text{if $i = 0$}.
  \end{cases}
\]
where $c \in \Lambda$ is referred to as {\em crossover type}. Classical crossover types 
include {\em 1-point crossover} and {\em uniform crossover}. For {\em 1-point crossover},
\[
  c_i =\begin{cases}
    1/(\ell - 1) & \text{if $\exists k \in (0, \ell).i = 2^k - 1$}.\\
    0 & \text{otherwise}.
  \end{cases}
\]
and for uniform crossover, $c_i = 2^{-\ell}$.

\subsection{Mixing Matrix}
The combined action of mutation and crossover is referred to as {\em mixing}.
The {\em mixing matrix\/} $M$ is the transmission matrix corresponding to the 
additive identity of $\mathcal{R}$
\[
M \; = \; M_{\bf 0}\\[-0.01in]
\]
Crossover and mutation are defined in a manner respecting arbitrary partioning and 
arbitrary linkage to preserve the ability to endow abstract syntax with specialized 
semantics. Groups of loci can mutate and crossover with arbitrarily specified 
probabilities as disscussed in above sections. For mutation distribution $\bm{\mu}$ and 
crossover distribution $\bm{\chi}$, the transmission function can be expressed as (see \cite{VoseWright1998})
\begin{equation}
\label{transmission}
t_{\langle u,v \rangle}(g) \; = \;\,
\sum_{i \nudge \in \nudge \mathcal{R}} \, \sum_{j \nudge \in \nudge \mathcal{R}} \,
\sum_{k \nudge \in \nudge \mathcal{R}}
\bm{\mu}_i \nudge \bm{\mu}_j \, \frac{\bm{\chi}_k + \bm{\chi}_{\overline{k}}}{2} \,
[\nudge k (u + i) + \overline{k}(v + j) \, = \, g\nudge]
\end{equation}
Here a child gamete $g$ is produced via mutation and then crossover (which are operators that
commute). 

The mixing matrix $M$ is a fundamental object, because (\ref{transmission}) implies that 
evolution equation (\ref{model3}) can be expressed in the form
\begin{equation}
\label{model4}
p_g^\prime \; = \; (\sigma_g \nudge p)^T M \, (\sigma_g \nudge p)
\end{equation}
where the permutation matrix $\sigma_g$ is defined by component equations
\[
(\sigma_g)_{u,v} \; = \; [\nudge u+v = g\nudge ]
\]

\section{Walsh Transorm}
If $n \in \mathcal{R}$ and $t \in \mathcal{R}$, and $N$ is the cardinality of $\mathcal{R}$, 
the Walsh matrix is defined by
\begin{equation}
\label{WalshT}
W_{n,t} = N^{-1/2} (-1)^{n^T t}
\end{equation}
where $N^{-1/2}$ can be thought of as a normalization factor.

The matrix is symmetric, i.e.,
\[
W_{n,t} = W_{n,t}
\]
and it has entries satisfying
\[
W_{n, t + k} = N^{1/2} W_{n, t} W_{n, k}  ;  \hspace{1cm}  k \in \mathcal{R}.
\]
The practical importance of this symmetry is that the transform and inverse 
are the same mathematical operation, and \textit{Walsh matrix} is its own inverse,
\[
W = W^{-1}.
\]
Given vector $w$ and matrix $A$, let $\widehat{w}$ and
$\widehat{A}$ denote the Walsh transform of $w$ and $A$ respectively. Then $\widehat{w} = Ww$ and
$\widehat{A} = WAW$ (see \cite{Beauchamp1975}).

\subsection{Fast Walsh Transform}
Computation of the discrete Walsh transform given by equation (\ref{WalshT}) might take $n^2$ operations 
(addition or subtraction) if implemented naively.
An algorithm using $O(n \log_2 n)$ operations is the Fast Walsh transform (FWT). 
Shanks (see \cite{Shanks1969}) described FWT algorithm which is analogous to 
Cooley-Tukey algorithm (see \cite{CooleyTukey1965}) for fast Fourier transformation.
The algorithm for FWT can be translated into pseudocode as:
\begin{algorithm}[ht]
\caption{FWT pseudocode}
\label{FWTpseudo}
\begin{algorithmic}[1]
\Procedure{FWT}{}

\State $n = 2^d   \gets $  size of array $X$ where $d$ is positive integer
\For{$i = 0$ to $d-1$ }
\State $m = n/2^i$
\State $z = m/2$
\For{$j = 0$ to $2^i-1$}
\For{$k = 0$ to $z-1$}
\State $t1 = m \times j + k$
\State $t2 = m \times j + z +k$
\State $a = X[t1]$
\State $b= X[t2]$
\State $X[t1] = a + b$
\State $X[t2] = a - b$
\EndFor
\EndFor
\EndFor
\State \Return $X$
\EndProcedure
\end{algorithmic}
\end{algorithm}

\subsection{Walsh Transform Adaptation}
 We adapt Walsh transform methods which have already been
established for Vose's haploid model (see \cite{VoseWright1998})
for computing evolutionary trajectories, making feasible
computation-based comparisons between finite and infinite
diploid population short-term evolutionary behavior.
Evolution equation (\ref{model4}), 
specialized to Vose's infinite population model without selection, 
is simplified by changing basis to diagonalize the $\sigma_g$.
% \[
% p_g^\prime \; = \; (\sigma_g \nudge p)^T M \, (\sigma_g \nudge p)
% \]
% where the permutation matrix $\sigma_g$ is defined by component
% equations
% \[
% (\sigma_g)_{u,v} \; = \; [\nudge u+v = g\nudge ]
% \]
% The Walsh matrix $W$ is defined by the component equations
% \[
% W_{u,v} \; = \; 2^{-\ell/2} (-1)^{u^T v}
% \]
% where the subscripts \nudge u, \nudge v (which belong to $\mathcal{R}$) on the left hand side 
% are interpreted on the right hand side as column vectors in $\mathbb{R}^{\ell}$.
Columns of the Walsh matrix $W$ form the orthonormal basis --- the
{\em Walsh basis\/} --- which simultaneously diagonalizes the
$\sigma_g$. Expressed in the Walsh basis (see \cite{VoseWright1998}), the mixing matrix
takes the form
\begin{equation}
\label{Mhat}
\widehat{M}_{u,v} \; = \; 2^{\,\ell-1} \,[\nudge u \nudge v = {\bf
    0}\nudge]\, \widehat{\bm{\mu}}_u \nudge \widehat{\bm{\mu}}_v \!  \sum_{k
  \nudge \in \nudge \overline{u+v} \nudge \mathcal{R}} \bm{\chi}_{k + u} +
\bm{\chi}_{k + v}
\end{equation}
and equation (\ref{model4}) takes the form
\begin{equation}
\label{model5}
\widehat{p}_g^{\,\,\prime} \; = \; 2^{\,\ell/2} \sum_{i \nudge \in \nudge g \mathcal{R}}
\widehat{p}_i \, \nudge \widehat{p}_{i+g} \,\widehat{M}_{i,i+g}
\end{equation}
where $g \mathcal{R} = \{g \nudge i \, | \, i \in \mathcal{R} \}$ (for
any $g \in \mathcal{R}$).

The mapping from generation $n$ to generation $n+1$, determined in
natural coordinates by equation (\ref{model3}) in terms of the
transmission function (\ref{Mg}), and given in Walsh coordinates by
equation (\ref{model5}) in terms of the mixing matrix (\ref{Mhat}), is
Markovian; the next state $p^\prime$ depends only upon the current
state $p$.  Let $\mathcal{M}$ represent the mixing transformation,
\begin{equation} \label{mixing_transformation}
p^\prime \; = \; \mathcal{M}(p)
\end{equation}
and let $\mathcal{M}^n(p)$ denote the $n$-fold composition of
$\mathcal{M}$ with itself; thus generation $n+1$ is described by
\[
p^{n+1} \; = \; \mathcal{M}^n(p^1)
\]
where $p^1 = \pi (q^1)$.  We have little to say
about the matrix of the Markov chain corresponding to the mixing
transformation $\mathcal{M}$, because it is uncountable; each state is
a distribution vector $p$ describing a population. However, that is
not an obstacle to computing evolutionary trajectories;
(\ref{mixing_transformation}) can be computed in Walsh coordinates
relatively efficiently via (\ref{Mhat}) and (\ref{model5}).
